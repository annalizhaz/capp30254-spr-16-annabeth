{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "import random\n",
    "from sklearn import svm, ensemble\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, auc, precision_recall_curve\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ATTRIBUTE_DICT = {\"SeriousDlqin2yrs\" : \"Has Had Serious Delinquincy in Past 2 Years\",\\\n",
    " \"NumberOfTimes90DaysLate\": \"Number of Times Person was 90+ Days Late\", \\\n",
    " \"RevolvingUtilizationOfUnsecuredLines\" : \"Credit Card Usage\", \\\n",
    " \"NumberOfTime30-59DaysPastDueNotWorse\": \"Number of Times 30-59 Days Past Due\", \\\n",
    " \"DebtRatio\": \"Debt Ration\", \\\n",
    " \"NumberOfDependents\": \"Number of Dependents\", \\\n",
    " \"MonthlyIncome\": \"Monthly Income\", \\\n",
    " \"NumberOfOpenCreditLinesAndLoans\" : \"Number of Open Credit Lines and Loans\", \\\n",
    " \"NumberRealEstateLoansOrLines\": \"Number of Real Estate Loans or Lines\", \\\n",
    " \"NumberOfTime60-89DaysPastDueNotWorse\": \"Number of Times 60-89 Days Past Due\", \\\n",
    " \"age\": \"Age\", 'bins_age' : \"Age Range\", 'bins_MonthlyIncome' : \"Income Range\", \\\n",
    "                 'bins_RevolvingUtilizationOfUnsecuredLines' : \"Credit Card Usage Range\", \\\n",
    "                 'bins_DebtRatio' : 'Debt Ratio Range'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HISTO_PARAMS = {\"SeriousDlqin2yrs\" : {\"title\" : \"Individuals With and Without Serious Delinquancy in Past 2 Years\", \\\n",
    "    \"bins\" : 2, \"y_label\" : \"Number of Inividuals\"},\n",
    "    \"NumberOfTimes90DaysLate\": {\"title\" : \"Individuals by Number of Times Person was 90+ Days Late\", \"bins\": 3, \\\n",
    "    \"y_label\" : \"Number of Individuals\"},\n",
    "    \"RevolvingUtilizationOfUnsecuredLines\" : {\"title\" : \"Individuals by Credit Card Usage\", \"bins\": 10, \\\n",
    "    \"y_label\" : \"Number of Individuals\"},\n",
    "    \"NumberOfTime30-59DaysPastDueNotWorse\": {\"title\" : \"Individuals by Number of Times 30-59 Days Past Due\", \"bins\": 50, \\\n",
    "    \"y_label\" : \"Number of Individuals\"},\n",
    "    \"DebtRatio\": {\"title\" : \"Individuals by Debt Ration\", \"bins\": 20, \\\n",
    "    \"y_label\" : \"Number of Inidviduals\"},\n",
    "    \"NumberOfDependents\": {\"title\" : \"Individuals by Number of Dependents\", \"bins\": 20, \\\n",
    "    \"y_label\" : \"Number of Individuals\"},\n",
    "    \"MonthlyIncome\": {\"title\" : \"Individuals by Monthly Income\", \"bins\" : 30, \\\n",
    "    \"y_label\" : \"Number of Individuals\"},\n",
    "    \"NumberOfOpenCreditLinesAndLoans\" : {\"title\" : \"Individuals by Number of Open Credit Lines and Loans\", \"bins\": 20, \\\n",
    "    \"y_label\" : \"Number of Individuals\"},\n",
    "    \"NumberRealEstateLoansOrLines\": {\"title\": \"Individuals by Number of Real Estate Loans or Lines\", \"bins\" : 20, \\\n",
    "    \"y_label\" : \"Number of Inividuals\"},\n",
    "    \"NumberOfTime60-89DaysPastDueNotWorse\": {\"title\" : \"Individuals by Number of Times 60-89 Days Past Due\", \"bins\": 4, \\\n",
    "    \"y_label\" : \"Number of Individuals\"},\n",
    "    \"age\": {\"title\" : \"Individuals by Age\", \"bins\": 11, \\\n",
    "    \"y_label\" : \"Number of Individuals\"},\n",
    "    \"bins_age\": {\"title\" : \"Individuals by Age Range\", \"bins\": 11, \"bin_labels\" : [], \\\n",
    "    \"y_label\" : \"Number of Individuals\"},\n",
    "    \"bins_MonthlyIncome\": {\"title\" : \"Individuals by Monthly Income Range\", \"bins\": 11, \"bin_labels\" : [], \\\n",
    "    \"y_label\" : \"Number of Individuals\"},\n",
    "    \"bins_RevolvingUtilizationOfUnsecuredLines\": {\"title\" : \"Individuals by Credit Card Usage Range\", \"bins\": 11, \"bin_labels\" : [], \\\n",
    "    \"y_label\" : \"Number of Individuals\"},\n",
    "    \"bins_DebtRatio\": {\"title\" : \"Individuals by Debt Ratio Range\", \"bins\": 11, \"bin_labels\" : [], \\\n",
    "    \"y_label\" : \"Number of Individuals\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODELS = {'RF': RandomForestClassifier(n_estimators=50, n_jobs=-1),\n",
    "    'LR': LogisticRegression(penalty='l1', C=1e5),\n",
    "    'SVM': svm.SVC(kernel='linear', probability=True, random_state=0),\n",
    "    'GB': GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=10),\n",
    "    'DT': DecisionTreeClassifier(),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=3),\n",
    "    'BAG': BaggingClassifier()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_in (path, source_type, has_index=False):\n",
    "    '''\n",
    "    Read in data.\n",
    "    \n",
    "    Takes path to data file, string indicating type of data storage,\n",
    "    and indicator of whether data includes an index (N/A for json)\n",
    "    \n",
    "    Returns pandas DataFrame\n",
    "    '''\n",
    "    if source_type.lower() == \"csv\":\n",
    "        if has_index:\n",
    "            index_col_number=0\n",
    "        else:\n",
    "            index_col_number=None\n",
    "        return pd.read_csv(path, index_col=index_col_number, header=0)\n",
    "    if source_type.lower() == \"excel\":\n",
    "        if has_index:\n",
    "            index_col_number=0\n",
    "        else:\n",
    "            index_col_number=None\n",
    "        return pd.read_excel(path, index_col=index_col_number)\n",
    "    if source_type.lower() == \"json\":\n",
    "        return pd.read_json(path)\n",
    "    if source_type.lower() == \"stata\":\n",
    "        if has_index:\n",
    "            index_col_number=0\n",
    "        else:\n",
    "            index_col_number=None\n",
    "        return pd.read_csv(path, index=index_col_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_description(df, save_to_file_name):\n",
    "    df1 = df.describe().T\n",
    "    modes = df.mode().T\n",
    "    modes.rename(columns={0 : \"mode\"}, inplace = True)\n",
    "    medians = pd.DataFrame(df.median())\n",
    "    medians.rename(columns={0 : \"median\"}, inplace = True)\n",
    "    stats_final = df1.join(modes, how=\"left\").join(medians, how=\"left\")\n",
    "    stats_final.to_csv(save_to_file_name)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def histo_plot(df, x_label, y_label, title, bins, bin_locs, limits, axis):\n",
    "    plt.clf()\n",
    "    plt.rcParams[\"figure.figsize\"] = [18.0, 8.0]\n",
    "    plt.hist(df, bins)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.axis(axis)\n",
    "    plt.grid(True)\n",
    "    plt.xticks(bin_locs)\n",
    "    plt.xlim(limits)\n",
    "    plt.savefig(\"results/\" + x_label + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(current_model, train_data, train_results):\n",
    "    model = current_model\n",
    "    model.fit(train_data, train_results)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(model, test_data):\n",
    "    predicted_results = model.predict(test_data)\n",
    "    return predicted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_model(predicted_results, actual_results):\n",
    "    acc = accuracy_score(actual_results, predicted_results)\n",
    "    prec = precision_score(actual_results, predicted_results)\n",
    "    rec = recall_score(actual_results, predicted_results)\n",
    "    f1 = f1_score(actual_results, predicted_results)\n",
    "    prec_curve, rec_curve, pr_thresholds = precision_recall_curve(actual_results, predicted_results)\n",
    "    return acc, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splits(df, train_portion):\n",
    "    rand_list = random.sample(range(len(df)), len(df))\n",
    "    divide_point = int(train_portion*len(df))\n",
    "    train_list = rand_list[:divide_point]\n",
    "    test_list = rand_list[divide_point:]\n",
    "    train_df = df.iloc[train_list, :]\n",
    "    test_df = df.iloc[test_list, :]\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def impute(data, column, imp_data, method):\n",
    "    '''\n",
    "    (adapted from Dani)\n",
    "    '''\n",
    "    if method == 'median':\n",
    "        median = imp_data.median()\n",
    "        data[column].fillna(median, inplace=True)\n",
    "        return median\n",
    "    elif method == 'mode':\n",
    "        mode = int(imp_data.mode()[0])\n",
    "        data[column].fillna(mode,  inplace=True)\n",
    "        return mode \n",
    "    else:\n",
    "        mean = imp_data.mean()\n",
    "        data[column].fillna(mean,  inplace=True)\n",
    "        return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_loop(train_data, test_data, train_results, test_results, model_dict=MODELS):\n",
    "    results_header = [\"accuracy\", \"precision\", \"recall\", \"F1\", \"AUC\"]\n",
    "    results_index = []\n",
    "    results = []\n",
    "    for abbr, model in model_dict.items():\n",
    "        print(abbr)\n",
    "        results_index.append(abbr)\n",
    "        model_t = build_model(model, train_data, train_results)\n",
    "        predicted_results = test_model(model_t, test_data)\n",
    "        acc, prec, rec, f1 = eval_model(predicted_results, test_results)\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            pred_prob = model_t.predict_proba(test_data)[:,1]\n",
    "        else:\n",
    "            pred_prob = model_t.decision_function\n",
    "        print(pred_prob)\n",
    "        precision_curve, recall_curve, thresholds = precision_recall_curve(test_results, pred_prob)\n",
    "        precision = precision_curve[:-1]\n",
    "        recall = recall_curve[:-1]\n",
    "        AUC = auc(recall, precision)\n",
    "        results.append([acc, prec, rec, f1, AUC])\n",
    "    final_results = pd.DataFrame(results, index=results_index, columns=results_header)\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_features(train, test):\n",
    "    '''\n",
    "    Adapted from Dani\n",
    "    '''\n",
    "    revolve_bins = [0, 0.029867442, 0.154180737, 0.559046248, 50709]\n",
    "    debt_bins = [0, 0.175073832, 0.366507841, 0.868253773, 329664]\n",
    "    income_bins = list(range(0, 10000, 1000)) + [train['MonthlyIncome'].max()]\n",
    "    age_bins = [0] + list(range(20, 80, 5)) + [120]\n",
    "\n",
    "    age_bucket = create_bins(train, 'age', age_bins)\n",
    "    income_bucket = create_bins(train, 'MonthlyIncome', income_bins)\n",
    "    cat_creditrev = create_bins(train, \"RevolvingUtilizationOfUnsecuredLines\", revolve_bins)\n",
    "    debt_bucket = create_bins(train, \"DebtRatio\", debt_bins)\n",
    "\n",
    "    age_bucket = create_bins(test, 'age', age_bins)\n",
    "    income_bucket = create_bins(test, 'MonthlyIncome', income_bins)\n",
    "    cat_creditrev = create_bins(test, \"RevolvingUtilizationOfUnsecuredLines\", revolve_bins)\n",
    "    debt_bucket = create_bins(test, \"DebtRatio\", debt_bins)\n",
    "\n",
    "    return age_bucket, income_bucket, cat_creditrev, debt_bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_bins(data, column, bins, verbose=False):\n",
    "    '''\n",
    "    Adapted from Dani\n",
    "    '''\n",
    "    new_col = 'bins_' + str(column)\n",
    "\n",
    "    data[new_col] = pd.cut(data[column], bins=bins, include_lowest=True, labels=False)\n",
    "\n",
    "    if verbose:\n",
    "        print(pd.value_counts(data[new_col]))\n",
    "\n",
    "    return new_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def go(read_file, write_desc, write_results, train_portion, predicted_col):\n",
    "    # Read in data to DataFrame\n",
    "    df = read_in(read_file, \"csv\", has_index = True)\n",
    "\n",
    "    # Generate description of data\n",
    "    get_description(df, \"results/description.csv\")    \n",
    "    \n",
    "    # Split data, prepare for use\n",
    "    train_df, test_df = splits(df, train_portion)\n",
    "    train_data = train_df.drop(predicted_col, axis=1)\n",
    "    train_results = train_df[predicted_col]\n",
    "    test_data = test_df.drop(predicted_col, axis=1)\n",
    "    test_results = test_df[predicted_col]\n",
    "    \n",
    "    # Impute missing values\n",
    "    impute(train_data, \"MonthlyIncome\", train_data[\"MonthlyIncome\"], \"median\")\n",
    "    impute(test_data, \"MonthlyIncome\", train_data[\"MonthlyIncome\"], \"median\")\n",
    "    impute(train_data, \"NumberOfDependents\", train_data[\"NumberOfDependents\"], \"mode\")\n",
    "    impute(test_data, \"NumberOfDependents\", train_data[\"NumberOfDependents\"], \"mode\")\n",
    "    train_data.to_csv(\"results/train_after_impute.csv\")\n",
    "    \n",
    "    # Alter columns with features, drop original\n",
    "    added_features = generate_features(train_data, test_data)\n",
    "    train_data.drop(['MonthlyIncome', 'age', 'DebtRatio', 'RevolvingUtilizationOfUnsecuredLines'], axis=1, inplace = True)\n",
    "    test_data.drop(['MonthlyIncome', 'age', 'DebtRatio', 'RevolvingUtilizationOfUnsecuredLines'], axis=1, inplace = True)\n",
    "    print(train_data.columns)\n",
    "    train_data.to_csv(\"results/train_after_alter.csv\")\n",
    "    test_data.to_csv(\"results/test_after_alter.csv\")\n",
    "    \n",
    "    # Generate histograms for all columns\n",
    "\n",
    "    for attribute in df.columns:\n",
    "        x_label = ATTRIBUTE_DICT[attribute]\n",
    "        y_label = HISTO_PARAMS[attribute][\"y_label\"]\n",
    "        title = HISTO_PARAMS[attribute][\"title\"]\n",
    "        column_data = df[attribute].dropna()\n",
    "        val_counts = column_data.value_counts()\n",
    "        col_max = column_data.max()\n",
    "        col_min = column_data.min()\n",
    "        axis = [col_min, col_max, 0, val_counts.iloc[0]*1.2]\n",
    "        #bin_count = HISTO_PARAMS[attribute][\"bins\"]\n",
    "        unique_ans = column_data.nunique()\n",
    "        if unique_ans > 20:\n",
    "            bin_count = 20\n",
    "        else:\n",
    "            bin_count = unique_ans\n",
    "        inc = (col_max-col_min)/bin_count\n",
    "        bins = np.array([x*inc + col_min for x in range(bin_count + 2)]) - inc/2 # +1 for alignment\n",
    "        bin_locs = np.array([x*inc + col_min for x in range(bin_count + 1)])\n",
    "        limits = [col_min-inc, col_max+inc]\n",
    "        histo_plot(column_data, x_label, y_label, title, bins, bin_locs, limits, axis)\n",
    "    \n",
    "    # Loop through models\n",
    "    results = model_loop(train_data, test_data, train_results, test_results)\n",
    "    results.to_csv(write_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "go(\"cs-training.csv\", \"results/description2.csv\", \"results/model_results.csv\", .8, \"SeriousDlqin2yrs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
